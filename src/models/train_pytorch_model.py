import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import torch
import torch.nn as nn
from tqdm import tqdm

#### FUNCTIONS AND CLASSES TO ASSIST WITH PYTORCH MODEL TRAINING AND VALIDATION ####
#### RUN TRAINING_LOOP() FUNCTION TO TRAIN MODEL WITH EARLY STOPPING ####

def count_parameters(model):
    """Count the number of trainable parameters in a model"""
    return sum(p.numel() for p in model.parameters() if p.requires_grad)

def train_one_epoch(model, criterion, optimizer, dataloader_train):
    """
    Train the model one epoch
    Params:
    model -- PyTorch model
    criterion -- function to evaluate losses
    optmizer -- Pytorch optimizer
    dataloader_train -- Pytorch dataloader for training data
    Return training loss (averaged for over each minibatch) for the epoch
    """

    # training loop
    total_loss = 0
    model.train() # set model to training mode
    for inputs, targets in dataloader_train:
        optimizer.zero_grad()

        # forward pass
        outputs = model(inputs)

        # Calculate loss with masked targets
        loss = criterion(outputs, targets)

        # Backward pass and optimization step
        loss.backward()
        optimizer.step()

        total_loss += loss.item()

    avg_loss = total_loss / len(dataloader_train)
    return avg_loss

def val_one_epoch(model, criterion, dataloader_val):
    """
    Calculate validation loss for a given epoch
    Params:
    model -- PyTorch model
    criterion -- function to evaluate losses
    dataloader_val -- Pytorch dataloader for validation data
    Return validation loss (averaged for over each minibatch) for the epoch
    """

    model.eval()  # Set the model to evaluation mode
    with torch.no_grad():
        total_val_loss = 0
        for val_inputs, val_targets in dataloader_val:
            # forward pass
            val_outputs = model(val_inputs)

            # evaluate validation loss
            val_loss = criterion(val_outputs, val_targets)
            total_val_loss += val_loss.item()

        avg_val_loss = total_val_loss / len(dataloader_val)
    return avg_val_loss

class EarlyStopper:
    """Implement EarlyStopper callback to prevent overfitting"""
    def __init__(self, patience=1, min_delta=0):
        self.patience = patience
        self.min_delta = min_delta
        self.counter = 0
        self.min_validation_loss = np.inf

    def early_stop(self, validation_loss):
        if validation_loss < self.min_validation_loss:
            self.min_validation_loss = validation_loss
            self.counter = 0
        elif validation_loss > (self.min_validation_loss + self.min_delta):
            self.counter += 1
            if self.counter >= self.patience:
                return True
        return False
    
def training_loop(model, criterion, optimizer, patience, dataloader_train, dataloader_val, epochs):
    """
    Run full training loop with early stopping.
    Params:
    model -- PyTorch model to train
    criterion -- function to evaluate loss
    optimizer -- PyTorch optimizer
    patience -- number of patience epochs for the early stopper
    dataloader_train -- PyTorch Dataloader for training data
    dataloader_val -- PyTorch Dataloader for validation data
    epochs -- maximum number of training epochs

    Returns:
    train_losses -- average training losses for each epoch
    val_losses -- average validation losses for each epoch
    """

    num_epochs = epochs
    train_losses = [] # keep track of training and val losses for Model 1
    val_losses = []
    early_stopper = EarlyStopper(patience=patience) # instantiate early stopper
    for epoch in tqdm(range(num_epochs), desc='Training epochs: '):
        # run training loop for current epoch
        model.train()
        train_loss = train_one_epoch(model, criterion, optimizer, dataloader_train)
        train_losses.append(train_loss)
        # run validation loop for current epoch
        model.eval()
        val_loss = val_one_epoch(model, criterion, dataloader_val)
        val_losses.append(val_loss)

        if early_stopper.early_stop(val_loss):
            break
    return train_losses, val_losses

def plot_train_val(train_losses, val_losses, ax=None):
    """
    Plot train and validation losses vs epochs after running training loop
    Params:
    train_losses -- list, training losses per epoch
    val_losses -- list, validation losses per epoch
    ax -- matplotlib axes, if provided
    """
    assert len(train_losses) == len(val_losses)
    if ax is not None:
        ax.plot(train_losses)
        ax.plot(val_losses)
        ax.legend(['training loss', 'validation loss'])
        ax.set_xlabel('Epochs')
        ax.set_ylabel('Loss')
    else:
        plt.clf()
        plt.plot(train_losses)
        plt.plot(val_losses)
        plt.legend(['training loss', 'validation loss'])
        plt.xlabel('Epochs')
        plt.ylabel('Loss')

def final_error(val_losses):
    """ 
    Print the final validation loss and the number of training epochs
    """
    print(f'Final validation loss: {val_losses[-1]}, Epochs trained: {len(val_losses)}')