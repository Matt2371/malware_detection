### TUNE LOGISTIC REGRESSION MODEL USING K-FOLD CV AND EXHAUSTIVE SEARCH ###


import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import KFold

from src.models.grid_search import grid_search
from src.models.k_fold_cv import LG_cv
from src.data_processing.feature_selection import rf_feature_selection

def avg_logistic_cv(k_folds, X, y, C=1, penalty='l2'):
    """
    Corresponds to avg_cv argument in models.grid_search.grid_search() for logistic regression
    Evaluate logistic regression under k-fold cross validation on the training data
    and return average performance over folds.
    """

    # Get k-fold indices
    kf = KFold(n_splits=k_folds, random_state=1, shuffle=True)

    # Get average results over k folds
    cross_val = LG_cv(X=X, y=y, kf=kf, C=C, penalty=penalty) # instantiate cross validation object for logistic regression
    cross_val.run_cv()
    avg_result = cross_val.average_perf()
    return avg_result

def main(n_top_features):
    # Read training data
    df = pd.read_csv('data/data_train.csv')
    X, y = df.drop(['Result'], axis=1), df.Result

    # Calculate feature importance
    rf_features = rf_feature_selection()
    rf_features.fit(X=X, y=y)
    sorted_features = rf_features.sorted_features

    # Select n top features
    X = X.loc[:, sorted_features[:n_top_features]]

    # Define search space
    C_array = np.arange(start=0.1, stop=0.3, step=0.1)
    arrays = [C_array]
    names = ['C']

    # Conduct k-fold CV over grid search
    result = grid_search(X=X, y=y, arrays=arrays, names=names, avg_cv=avg_logistic_cv)

    # Save results as csv
    result.to_csv('report/results/hyperparameter_tuning/logistic_regression_grid_search.csv', index=False)
    return

# run script
if __name__ == '__main__':
    main(n_top_features=40)
